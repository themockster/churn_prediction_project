{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e30d3cd-870d-447d-a34a-125a5697ef3b",
   "metadata": {},
   "source": [
    "## Preprocessing the Telco Customer Churn Dataset\n",
    "\n",
    "### Objective\n",
    "In this notebook, we will preprocess the Telco Customer Churn dataset to prepare it for machine learning. The steps include:\n",
    "1. Encoding categorical variables into numerical formats.\n",
    "2. Scaling numerical features to normalize their ranges.\n",
    "3. Splitting the data into training and testing sets for model evaluation.\n",
    "\n",
    "This step is critical for ensuring that the dataset is ready for modeling in the next phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e3e6cd-402f-420e-bb3b-90217dbc3566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c0ee6f-56cc-416c-a27c-24f69a13dd01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33762b9-b3e3-40d3-a6a9-d5522b8ef7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcd669be-b8ee-4710-8833-68616df9c6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72617556-6af6-4ba0-9753-ad4a4a19076a",
   "metadata": {},
   "source": [
    "## Step 1: Loading the data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4565b615-42aa-48d8-8a8b-0187088ab492",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "file_path = os.path.join(project_root, 'data/raw/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "data = pd.read_csv(file_path)\n",
    "# if you wish to validate the first initial rows for proper loading, uncomment the below print.\n",
    "# print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bd690a-269c-4d3d-8c81-c549ccfb6b96",
   "metadata": {},
   "source": [
    "## Step 2 : Defining Features and Target\n",
    "\n",
    "Let's split our data set into features and target. \n",
    "\n",
    "We want the features that will influence churn and our prediction target is the Churn column.\n",
    "\n",
    "A customer ID is also not relevant for our analysis, as it has no impact on our prediction target, so we will drop that column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "decf829a-0f66-40f9-8f50-1f2ba4fc5484",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['customerID', 'Churn']) # we drop the irrelvant column and the target column\n",
    "Y = data['Churn'].apply(lambda x: 1 if x == 'Yes' else 0) # we convert our Churn Data into binary numbers, as our framework cannot work with the data as it exists\n",
    "# You can uncomment the below prints to check the result \n",
    "#print(X.head())\n",
    "#print(X.columns)\n",
    "#print(Y.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adedb328-c752-4a91-9d2b-434d83e6dced",
   "metadata": {},
   "source": [
    "## Step 3 : Identifying columns that are categorical and numerical\n",
    "\n",
    "### Why Is This Step Important?\n",
    "In this step, we separate the dataset into **categorical columns** and **numerical columns**. This distinction is crucial because:\n",
    "- Machine learning models treat numerical and categorical data differently.\n",
    "- Categorical data needs to be encoded into numerical formats before being passed to the model.\n",
    "- Numerical data often needs scaling or normalization to ensure uniform ranges for all features.\n",
    "\n",
    "By identifying categorical and numerical columns early, we can apply the appropriate preprocessing techniques to each type of data.\n",
    "\n",
    "\n",
    "### Understanding \"No Internet Service\"\n",
    "In the Telco Customer Churn dataset, some columns (e.g., `InternetService`) may include a value like `\"No Internet Service\"`. This is important to understand because:\n",
    "- It represents a category where the customer has **no internet service**, rather than being a missing or invalid value.\n",
    "- If we treat this value incorrectly (e.g., as missing data), we could lose important information.\n",
    "\n",
    "### How We Address It:\n",
    "1. **Treat \"No Internet Service\" as a Valid Category**:\n",
    "   - When encoding categorical features, `\"No Internet Service\"` will be treated as one of the valid categories and converted into a one-hot encoded column (e.g., a binary column where `1` indicates `\"No Internet Service\"`).\n",
    "\n",
    "2. **Ensure Consistency Across Features**:\n",
    "   - Columns like `OnlineSecurity`, `OnlineBackup`, and similar services also have `\"No Internet Service\"` as a value, which indicates the customer does not have internet. These will also be treated as valid categories.\n",
    "\n",
    "### Example:\n",
    "Suppose the `InternetService` column contains the following values:\n",
    "```\n",
    "['DSL', 'Fiber optic', 'No Internet Service']\n",
    "```\n",
    "After one-hot encoding, these values will become:\n",
    "```\n",
    "DSL: [1, 0, 0]\n",
    "Fiber optic: [0, 1, 0]\n",
    "No Internet Service: [0, 0, 1]\n",
    "```\n",
    "This ensures that the model can learn from customers without internet service as a separate category.\n",
    "\n",
    "\n",
    "### Some additional data types may be required\n",
    "In some datasets, additional data types may exist, requiring specific handling. For example:\n",
    "\n",
    "1. **Datetime Columns**:\n",
    "   - If the dataset has dates (e.g., `signup_date` or `last_activity`), you may need to:\n",
    "     - Extract useful features (e.g., month, day of the week, or the difference between two dates).\n",
    "     - Convert these columns into numerical formats or cyclic representations (e.g., sine and cosine encoding for months).\n",
    "\n",
    "     ```python\n",
    "     X['signup_month'] = X['signup_date'].dt.month  # Extract month from date\n",
    "     ```\n",
    "\n",
    "2. **Boolean Columns**:\n",
    "   - Columns with `True`/`False` values (e.g., `Has_Contract`) can be directly converted into `1` and `0`.\n",
    "\n",
    "     ```python\n",
    "     X['Has_Contract'] = X['Has_Contract'].astype(int)\n",
    "     ```\n",
    "\n",
    "3. **Text Columns**:\n",
    "   - For text data (e.g., `comments` or `feedback`), you may need:\n",
    "     - Natural Language Processing (NLP) techniques, such as tokenization or embedding models like TF-IDF or Word2Vec.\n",
    "\n",
    "4. **Mixed-Type Columns**:\n",
    "   - Some columns may contain a mix of numbers and strings (e.g., \"10GB\" or \"Unlimited\"). These need manual intervention to extract meaningful numerical features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "204134e6-beb1-47c9-a12a-4b0b2ca601e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: Index(['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',\n",
      "       'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
      "       'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',\n",
      "       'PaperlessBilling', 'PaymentMethod', 'TotalCharges'],\n",
      "      dtype='object')\n",
      "Numerical columns: Index(['SeniorCitizen', 'tenure', 'MonthlyCharges'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = X.select_dtypes(include=['object']).columns # categorical columns are represented by an object in the panda dataset\n",
    "numerical_columns = X.select_dtypes(include=['int64','float64']).columns\n",
    "\n",
    "print(\"Categorical columns:\", categorical_columns)\n",
    "print(\"Numerical columns:\", numerical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6bee86-a8f4-48eb-9f47-e6e9ea9c23d1",
   "metadata": {},
   "source": [
    "## Step 4: Building a Preprocessing Pipeline\n",
    "\n",
    "### Why Do We Need a Preprocessing Pipeline?\n",
    "To ensure our data is ready for machine learning, we need to preprocess it into interpretable values. This involves two main tasks:\n",
    "\n",
    "1. **Normalizing Numerical Features**:\n",
    "   - Numerical features like `tenure` (which ranges from 0 to 72) and `MonthlyCharges` (which ranges from 0 to 200) are on different scales.\n",
    "   - Without normalization, these differences in scale can negatively impact the performance of many machine learning models by giving undue importance to features with larger ranges.\n",
    "   - Normalization ensures that all numerical features are on a similar scale, typically with a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "2. **Encoding Categorical Features**:\n",
    "   - Machine learning models require numerical inputs, so categorical features (e.g., `gender`, `InternetService`) must be converted into numerical formats.\n",
    "   - We use one-hot encoding to represent each category as a binary column. For example, a `gender` column with values `Male` and `Female` will be transformed into two columns: `Male` and `Female` with binary values (0 or 1).\n",
    "   - This step was discussed in more detail in Step 3.\n",
    "\n",
    "By combining these transformations into a preprocessing pipeline, we can ensure that our data is consistently prepared for both training and testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053fb8d7-ef6c-4c72-9e50-9f952413c5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('num', StandardScaler(), numerical_columns),\n",
    "        ('cat', OneHotEncoder(handle_unknown = 'ignore'), categorical_columns\n",
    "         ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3d68f6-6e5e-4893-bf38-af59d6c0532b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
