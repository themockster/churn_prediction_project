{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7714100-e48f-44a5-92b5-ca6d015cd869",
   "metadata": {},
   "source": [
    "# Churn Prediction: Data Ingestion and Preprocessing\n",
    "\n",
    "## Objective\n",
    "In this notebook, we will focus on the initial stages of the churn prediction project:\n",
    "- Loading the raw data from the **Telco Customer Churn** dataset.\n",
    "- Exploring the structure and contents of the dataset through **Exploratory Data Analysis (EDA)**.\n",
    "- Cleaning and preprocessing the data to make it ready for machine learning tasks.\n",
    "\n",
    "## Workflow\n",
    "1. **Load the Dataset**:\n",
    "   - Dynamically locate and load the dataset stored in the `data/raw/` directory.\n",
    "2. **Exploratory Data Analysis (EDA)**:\n",
    "   - Understand the dataset structure, including data types, missing values, and feature distributions.\n",
    "   - Identify any necessary transformations or cleaning steps.\n",
    "3. **Data Cleaning and Preprocessing**:\n",
    "   - Handle missing values, encode categorical variables, and scale numerical features.\n",
    "   - Save the cleaned and preprocessed dataset to the `data/processed/` directory for downstream tasks.\n",
    "\n",
    "---\n",
    "\n",
    "This notebook is part of the larger **Churn Prediction Project**, which aims to predict customer churn using machine learning. The processed data from this notebook will serve as input for model training and evaluation in subsequent steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35f1ea6e-7c4d-4efc-98b9-6f2e4ded2155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1 : Loading the dataset downloaded from Kaggle (see .scripts/kaggle_data_download.py)\n",
    "#This notebook is in the project directory, the project_root variable serves us to dynamically get to our data\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "file_path = os.path.join(project_root, 'data/raw/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "data = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff431d9e-60f5-4fb4-961e-ba46d0ea1a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of data\n",
      "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
      "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
      "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
      "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
      "3  7795-CFOCW    Male              0      No         No      45           No   \n",
      "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
      "\n",
      "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
      "0  No phone service             DSL             No  ...               No   \n",
      "1                No             DSL            Yes  ...              Yes   \n",
      "2                No             DSL            Yes  ...               No   \n",
      "3  No phone service             DSL            Yes  ...              Yes   \n",
      "4                No     Fiber optic             No  ...               No   \n",
      "\n",
      "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
      "0          No          No              No  Month-to-month              Yes   \n",
      "1          No          No              No        One year               No   \n",
      "2          No          No              No  Month-to-month              Yes   \n",
      "3         Yes          No              No        One year               No   \n",
      "4          No          No              No  Month-to-month              Yes   \n",
      "\n",
      "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
      "0           Electronic check          29.85         29.85    No  \n",
      "1               Mailed check          56.95        1889.5    No  \n",
      "2               Mailed check          53.85        108.15   Yes  \n",
      "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
      "4           Electronic check          70.70        151.65   Yes  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 2 : Preview the dataset by displaying the first few rows of the dataset to understand its structure and data\n",
    "print(\"First 5 rows of data\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bc38eb-d7d6-4d26-a89d-1cd7e45e188a",
   "metadata": {},
   "source": [
    "**You should have seen some rows and columns associated with the data file that we are working on**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e220d2b8-60e5-42b8-9265-d5983a6e2af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        7043 non-null   object \n",
      " 1   gender            7043 non-null   object \n",
      " 2   SeniorCitizen     7043 non-null   int64  \n",
      " 3   Partner           7043 non-null   object \n",
      " 4   Dependents        7043 non-null   object \n",
      " 5   tenure            7043 non-null   int64  \n",
      " 6   PhoneService      7043 non-null   object \n",
      " 7   MultipleLines     7043 non-null   object \n",
      " 8   InternetService   7043 non-null   object \n",
      " 9   OnlineSecurity    7043 non-null   object \n",
      " 10  OnlineBackup      7043 non-null   object \n",
      " 11  DeviceProtection  7043 non-null   object \n",
      " 12  TechSupport       7043 non-null   object \n",
      " 13  StreamingTV       7043 non-null   object \n",
      " 14  StreamingMovies   7043 non-null   object \n",
      " 15  Contract          7043 non-null   object \n",
      " 16  PaperlessBilling  7043 non-null   object \n",
      " 17  PaymentMethod     7043 non-null   object \n",
      " 18  MonthlyCharges    7043 non-null   float64\n",
      " 19  TotalCharges      7043 non-null   object \n",
      " 20  Churn             7043 non-null   object \n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Step 3 : Get Basic information using the info() method to get an overview of the data including column names, non-null counts and data types.\n",
    "print(\"\\nBasic information about the dataset:\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03323615-edee-4654-a60e-745b68be1b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary statistics for numerical columns:\n",
      "       SeniorCitizen       tenure  MonthlyCharges\n",
      "count    7043.000000  7043.000000     7043.000000\n",
      "mean        0.162147    32.371149       64.761692\n",
      "std         0.368612    24.559481       30.090047\n",
      "min         0.000000     0.000000       18.250000\n",
      "25%         0.000000     9.000000       35.500000\n",
      "50%         0.000000    29.000000       70.350000\n",
      "75%         0.000000    55.000000       89.850000\n",
      "max         1.000000    72.000000      118.750000\n"
     ]
    }
   ],
   "source": [
    "# Step 4 : Summary statistics for numerical columns to understand their distribution.\n",
    "print(\"\\nSummary statistics for numerical columns:\")\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6f4d5dc-c267-43b4-95a5-710e29da9d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values in each column:\n",
      "customerID          0\n",
      "gender              0\n",
      "SeniorCitizen       0\n",
      "Partner             0\n",
      "Dependents          0\n",
      "tenure              0\n",
      "PhoneService        0\n",
      "MultipleLines       0\n",
      "InternetService     0\n",
      "OnlineSecurity      0\n",
      "OnlineBackup        0\n",
      "DeviceProtection    0\n",
      "TechSupport         0\n",
      "StreamingTV         0\n",
      "StreamingMovies     0\n",
      "Contract            0\n",
      "PaperlessBilling    0\n",
      "PaymentMethod       0\n",
      "MonthlyCharges      0\n",
      "TotalCharges        0\n",
      "Churn               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 5:  Check for missing values by using isnull() and sum() to count missing values in each columns \n",
    "print(\"\\nMissing Values in each column:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fe6455d-d389-460b-8229-8b2eb2eed073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in categorical columns:\n",
      "customerID: ['7590-VHVEG' '5575-GNVDE' '3668-QPYBK' ... '4801-JZAZL' '8361-LTMKD'\n",
      " '3186-AJIEK']\n",
      "gender: ['Female' 'Male']\n",
      "Partner: ['Yes' 'No']\n",
      "Dependents: ['No' 'Yes']\n",
      "PhoneService: ['No' 'Yes']\n",
      "MultipleLines: ['No phone service' 'No' 'Yes']\n",
      "InternetService: ['DSL' 'Fiber optic' 'No']\n",
      "OnlineSecurity: ['No' 'Yes' 'No internet service']\n",
      "OnlineBackup: ['Yes' 'No' 'No internet service']\n",
      "DeviceProtection: ['No' 'Yes' 'No internet service']\n",
      "TechSupport: ['No' 'Yes' 'No internet service']\n",
      "StreamingTV: ['No' 'Yes' 'No internet service']\n",
      "StreamingMovies: ['No' 'Yes' 'No internet service']\n",
      "Contract: ['Month-to-month' 'One year' 'Two year']\n",
      "PaperlessBilling: ['Yes' 'No']\n",
      "PaymentMethod: ['Electronic check' 'Mailed check' 'Bank transfer (automatic)'\n",
      " 'Credit card (automatic)']\n",
      "TotalCharges: ['29.85' '1889.5' '108.15' ... '346.45' '306.6' '6844.5']\n",
      "Churn: ['No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Iterate through columns with object data types and print unique values\n",
    "print(\"\\nUnique values in categorical columns:\")\n",
    "for col in data.select_dtypes(include='object').columns:\n",
    "    print(f\"{col}: {data[col].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb89ae5-3232-4835-b2d3-8b65c05cc79b",
   "metadata": {},
   "source": [
    "## Handling Missing Values\n",
    "\n",
    "### Context: No Missing Values in This Dataset\n",
    "In this dataset, there are no missing values, so we do not need to handle any missing data. However, it's important to consider how missing values would be addressed in case they were present. Here’s what we would do if we encountered missing values in other datasets:\n",
    "\n",
    "### Approaches for Handling Missing Values\n",
    "1. **Drop Rows or Columns**:\n",
    "   - If the percentage of missing values in a column or row is very high (e.g., >50%), it might be reasonable to drop them.\n",
    "   - Example:\n",
    "     ```python\n",
    "     data.dropna(axis=0, inplace=True)  # Drop rows with missing values\n",
    "     data.dropna(axis=1, inplace=True)  # Drop columns with missing values\n",
    "     ```\n",
    "   **Identify rows with missing values**\n",
    "     ```python\n",
    "        missing_rows = data[data.isnull().any(axis=1)]\n",
    "        print(\"Rows with missing values:\")\n",
    "        print(missing_rows)\n",
    "    ```\n",
    "\n",
    "3. **Imputation (Filling Missing Values)**:\n",
    "   - Replace missing values with meaningful statistics (e.g., mean, median, or mode) or values inferred from other data.\n",
    "   - Examples:\n",
    "     - **Numerical Data**: Fill with mean or median.\n",
    "       ```python\n",
    "       data['NumericalColumn'].fillna(data['NumericalColumn'].mean(), inplace=True)\n",
    "       ```\n",
    "     - **Categorical Data**: Fill with the mode (most frequent value).\n",
    "       ```python\n",
    "       data['CategoricalColumn'].fillna(data['CategoricalColumn'].mode()[0], inplace=True)\n",
    "       ```\n",
    "\n",
    "4. **Predict Missing Values**:\n",
    "   - Use machine learning models to predict the missing values based on other features in the dataset. This is more advanced and useful when missing values are not random.\n",
    "\n",
    "5. **Use Domain Knowledge**:\n",
    "   - In some cases, domain expertise can help fill missing values with logical substitutes.\n",
    "   - Example: If a column \"Has_Internet_Service\" is missing and the \"InternetService\" column is \"No\", fill the missing values with \"No\".\n",
    "\n",
    "### Key Considerations\n",
    "- **Understand the Context**: Analyze the column's role in the dataset before deciding how to handle missing values.\n",
    "- **Avoid Bias**: Imputing with a mean or mode can introduce bias. Advanced techniques like KNN imputation can reduce this.\n",
    "- **Impact on Modeling**: Document how missing value handling might affect model performance and interpretations.\n",
    "\n",
    "Since there are no missing values in this dataset, we can skip this step and proceed with data preprocessing.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
